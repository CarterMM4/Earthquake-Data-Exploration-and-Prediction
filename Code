import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from google.colab import files
import os
import shutil

# Upload and configure kaggle.json
def setup_kaggle():
    os.makedirs('/root/.kaggle', exist_ok=True)
    files.upload()
    shutil.move('kaggle.json', '/root/.kaggle/kaggle.json')
    os.chmod('/root/.kaggle/kaggle.json', 600)

setup_kaggle()

# Download and unzip the dataset
!pip install -q kaggle
!kaggle datasets download -d usgs/earthquake-database
!unzip -o earthquake-database.zip

# Load the dataset
data = pd.read_csv('database.csv')  # Check the filename after download

# Inspect the dataset
print(data.info())
print(data.head())

# Drop irrelevant columns
data = data.drop(['ID', 'Location Source', 'Magnitude Source', 'Status'], axis=1, errors='ignore')

# Convert Date column to datetime format
data['Date'] = pd.to_datetime(data['Date'], errors='coerce')
data = data.dropna(subset=['Date'])  # Remove rows with invalid dates

# Fill missing values in numerical columns with median
for col in data.select_dtypes(include='float64').columns:
    data[col].fillna(data[col].median(), inplace=True)

# Fill missing values in categorical columns with 'Unknown'
data['Type'].fillna('Unknown', inplace=True)

# 1. **Exploratory Data Analysis (EDA)**

# Distribution of earthquake magnitudes
sns.histplot(data['Magnitude'], bins=20, kde=True, color='skyblue')
plt.title('Distribution of Earthquake Magnitudes')
plt.xlabel('Magnitude')
plt.ylabel('Frequency')
plt.show()

# Earthquakes by year
data['Year'] = data['Date'].dt.year
sns.countplot(data=data, x='Year', palette='viridis')
plt.title('Earthquake Frequency by Year')
plt.xlabel('Year')
plt.ylabel('Number of Earthquakes')
plt.xticks(rotation=45)
plt.show()

# Geographic distribution of earthquakes
plt.figure(figsize=(10, 6))
plt.scatter(data['Longitude'], data['Latitude'], c=data['Magnitude'], cmap='YlOrRd', alpha=0.5)
plt.colorbar(label='Magnitude')
plt.title('Geographic Distribution of Earthquakes')
plt.xlabel('Longitude')
plt.ylabel('Latitude')
plt.show()

# 2. **Feature Engineering**

# Generate additional features based on date
data['Month'] = data['Date'].dt.month
data['Day'] = data['Date'].dt.day

# Encode categorical feature 'Type'
data = pd.get_dummies(data, columns=['Type'], drop_first=True)

# Scale features for model training
numerical_features = ['Latitude', 'Longitude', 'Depth', 'Month', 'Day']
scaler = StandardScaler()
data[numerical_features] = scaler.fit_transform(data[numerical_features])

# 3. **Predictive Modeling** (Predicting Magnitude based on other factors)

# Define features (X) and target (y)
X = data.drop(['Magnitude', 'Date', 'Year'], axis=1)
y = data['Magnitude']

# Drop columns with time data if present
data = data.drop(['Time'], axis=1, errors='ignore')  # Adjust column name if needed

# Ensure all remaining columns are numeric
X = X.apply(pd.to_numeric, errors='coerce').fillna(0)  # Convert non-numeric to NaN, then fill with 0

# Reduce dimensionality with PCA
pca = PCA(n_components=5)
X_pca = pca.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=42)

# Train a Random Forest Regressor
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Predictions and evaluation
y_pred = model.predict(X_test)
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("R^2 Score:", r2_score(y_test, y_pred))

# Feature importance plot
plt.figure(figsize=(10, 6))
importances = model.feature_importances_
indices = range(len(importances))
plt.bar(indices, importances, color='royalblue')
plt.title('Feature Importance in Predicting Earthquake Magnitude')
plt.xlabel('Feature Index')
plt.ylabel('Importance')
plt.show()

